import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report

from knn.knn import my_knn
from knn.knn_vectorization import my_knn_vectorization

# Задача
# Маємо n картинок на яких зображені цифри, потрібно зробити алгоритм який зможе на їх основі
# передбачити що за цифра буде на іншій картинці
# 
# !Важлива примітка 
# Картинки мають бути однакового розміру, у нас 8x8. Це потрібно для того, що наш алгоритм KNN
# буде шукати подібні кольори пікселів між двома картинками і якщо вони обидві мають однакову цифру, 
# яка однаково намальована (нехай цифра 9) але, нехай на першій картинці знаходиться зліва, а на другій з права,
# то алгоритм дасть не вірну відповідь, адже він порівнює відстань між векторами (кольорами) (L2 - Евклідова норма). 
# Бо вийде що у першої картинки зліва будуть чорні пікселі (сама цифра), а з права білі (порожній простір),
# а у другої навпаки, зліва будуть білі (порожній простір), а з права чорні (сама цифра). І хоч цифра однакова і однаково
# намальована але відстань буде більшою ніж скажімо між цифрою 7, але яка теж намальована зліва.
# Саме тому тут в прикладі всі картинки однакового розміру і цифри на них теж +- однакового розміру


# ---- Крок 1: Завантаження та підготовка даних MNIST ----

# Завантажуємо набір даних рукописних цифр.
# Цей набір даних є меншою версією MNIST, але ідеально підходить для швидкої демонстрації.
# Це зображення розміром 8x8 пікселів.
digits = load_digits()

# 'digits.images' - [ [ [0., 0., 5., 13., 9., 1., 0., 0.],... ],... ] це 3D масив (кількість_зображень, висота, ширина). Довжина масиву 1797 
#       Цифри тут - це НЕ r,g,b - Це значення інтенсивності сірого кольору для кожного пікселя зображення. 
#       0 - означає, що піксель дуже темний (близький до чорного).
#       16 - (максимальне значення в цьому наборі даних) означає, що піксель дуже світлий (близький до білого).
#       Проміжні значення (як 5., 13., 9.) — це відтінки сірого. 
#       Дані представлені у вигляді інтенсивності кольору з таких міркувань: 
#           1. Зменшення розмірності. Тепер колір представлений лише 1 цифрою, а не масивом з 3. Це пришвидшує обрахунки
#               RGB-зображення вимагало б 8×8×3=192 ознаки.
#               Сіре зображення вимагає 8×8×1=64 ознаки 
#               Однакові за розміром зображення, але сіре простіше обчислити!
#           2. Природа інформації в задачі. Для розуміння того яка цифра намальована нам не потрібен колір, нам потрібно розуміти
#              лише її форму
#           3. Виключення надлишкових ознак. Додавання непотрібних ознак може навіть погіршити продуктивність моделі, 
#              створюючи "шум" або викликаючи "прокляття розмірності" (Curse of Dimensionality), коли в дуже високорозмірному
#              просторі дані стають розрідженими, і відстані втрачають своє значення
# 
# 
# Перший рівень [ ... ] Це список/масив всіх зображень у наборі даних.
# Тобто, digits.images[0] — це перше зображення, digits.images[1] — друге, і так далі. 
# 
# Другий рівень [ [0., 0., 5., 13., 9., 1., 0., 0.],... ]: Це одне конкретне зображення.
# Оскільки наші зображення мають розмір 8x8 пікселів, цей рівень є масивом рядків пікселів.
# Тобто довжина цього масиву масивів 8 елементів, кожен елемент якого теж містить 8 елементів
# 
# 'digits.data' - [ [0., 0., 5., 13., 9., 1., 0., 0.,...],... ] це 2D масив (кількість_зображень, кількість_пікселів) - ВЖЕ ВИРІВНЯНИЙ.
# тобто це масив масивів це кожен підмасив містить 64 цифри (8*8). Довжина масиву 1797
X = digits.data  # Ознаки (вирівняні зображення)

# 'digits.target' - [1,6,3,9,0,2,...] це мітки (справжні цифри) для кожного зображення 
# Довжина масиву 1797 елементів, кожен елемент це число яке посилається на намальоване число у digits.images чи digits.data
# Оскільки digits.target має таку саме довжину що і digits.images то перший елемент з digits.target відповідає 
# першому елементу з digits.images
y = digits.target # Мітки (справжні цифри від 0 до 9)

print(f"Загальна кількість зображень: {len(X)}")
print(f"Форма одного зображення (вирівняна): {X.shape[1]} пікселів") # Кожне зображення 8x8 = 64 пікселі
print(f"Перші 5 міток: {y[:5]}")

# Просто виводимо для кращого розуміння 5 зображень цифр і їх мітки
# Щоб знати які цифри зображені на картинках
plt.figure(figsize=(10, 4))
for i in range(5):
    plt.subplot(1, 5, i + 1)
    # digits.images[i] має форму (8, 8), тому може бути показано безпосередньо
    plt.imshow(digits.images[i], cmap=plt.cm.gray_r, interpolation='nearest')
    plt.title(f"Мітка: {y[i]}")
    plt.axis('off')
plt.suptitle("Приклади рукописних цифр")
plt.show()


# ---- Крок 2: Розділення даних на навчальну та тестову вибірки ----

# Розділяємо дані: 80% для навчання, 20% для тестування (на 20% які модель не бачила
# будемо перевіряти те, наскільки добре модель вміє розпізнавати цифри)
# 
# train_test_split розділяє дані випадковим чином. 
# Без random_state кожен раз, коли ти запускатимеш код, дані будуть розділятися по-різному.
# Це означає, що результати навчання та тестування моделі будуть трохи відрізнятися при кожному запуску. 
# 
# Встановлення random_state на певне ціле число (наприклад, 42, але може бути будь-яке ціле число)
# гарантує, що випадкове розділення буде однаковим щоразу, коли ти запускаєш код з тим самим random_state.
# Це дозволяє тобі та іншим перевіряти твої результати. 
# 
#
# digits.data - [ [0., 0., 5., 13., 9., 1., 0., 0.,...],... ] 
# X_train - має ту саму форму що і digits.data, просто має меншу довжину масиву за digits.data, лише 80% 
# X_test - той самий формат що і у X_train. Це дані для тестування (20% від digits.data)
# 
# y_train - це навчальний набір міток (labels) що відповідають кожному зображенню в X_train.
#           Це "правильні відповіді" для кожного навчального зображення. Тобто це буквально написані
#           цифрами ті цифри, що зображені на малюнках в X_train. Але цк не всі мітки, а лише 80%
#           Приклад - [5, 0, 4, 1, 9, 2, ...]
# y_test - решта 20% міток (labels) для тестування
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"Кількість зображень для навчання: {len(X_train)}")
print(f"Кількість зображень для тестування: {len(X_test)}")


# ---- Крок 3: Навчання моделі KNN та прогнозування ----


# K=3 означає, що ми будемо шукати 3 найближчих сусідів.
k_value = 3 
# y_pred = my_knn(X_train=X_train, y_train=y_train, X_test=X_test, k=k_value)
y_pred = my_knn_vectorization(X_train=X_train, y_train=y_train, X_test=X_test, k=k_value)

print(f"Прогнозування завершено. K = {k_value}")



# ---- Крок 4: Оцінка продуктивності моделі ----

# Оцінюємо точність моделі
# accuracy_score() бере y_test і y_pred та порівнює їх поелементно і обчислює, 
# яка частка прогнозів моделі збігається зі справжніми мітками 
# accuracy_score повертає число яке є відсотком того на скільки дані збігаються, наприклад 0.98333 - 98.3%
accuracy = accuracy_score(y_test, y_pred)
print(f"Точність моделі KNN (K={k_value}): {accuracy:.4f}")

print("\nЗвіт про класифікацію:")
# classification_report робить детальний аналіз роботи моделі
# precision (точність) - З усіх випадків, коли модель прогнозувала певний клас (наприклад, "це 5"),
# показує яка частка цих прогнозів була справді правильною 
#     Приклад: Якщо для цифри "8" Precision дорівнює 0.95, це означає, що 95% всіх разів,
#              коли модель сказала "це 8", це справді була "8".
#
# recall (повнота, чутливість): З усіх випадків, коли певний клас дійсно був присутній у даних
# (наприклад, "це справді була 5"), та яку частку з них модель успішно виявила
#     Приклад: Якщо для цифри "8" Recall дорівнює 0.97, це означає, що модель успішно виявила 97%
#              всіх справжніх "вісімок", які були в тестових даних 
# 
# support - Це кількість справжніх випадків (зразків) для кожного класу в тестовій вибірці.
#     Приклад: support 39 для "8" означає, що в тестових даних було 39 зображень справжньої цифри "8".
# 
# 
print(classification_report(y_test, y_pred))



# ---- Крок 5: Візуалізація кількох помилкових прогнозів (за бажанням) ----

# Знаходимо індекси, де прогнози не збігаються з реальними мітками
# Якщо треба то можна вивести ті які визначені правильно np.where(y_pred == y_test)[0]
misclassified_indices = np.where(y_pred != y_test)[0]

if len(misclassified_indices) > 0:
    plt.figure(figsize=(12, 6))
    plt.suptitle(f"Кілька помилкових прогнозів (K={k_value})", fontsize=16)
    
    # Показуємо до 10 помилкових прогнозів
    for i, bad_test_index in enumerate(misclassified_indices[:10]): # Змінив назву змінної на bad_test_index для ясності
        plt.subplot(2, 5, i + 1)
        # Використовуємо X_test[bad_test_index] (який є 1D вектором)
        # та переформовуємо його до оригінального розміру зображення (8x8)
        plt.imshow(X_test[bad_test_index].reshape(8, 8), cmap=plt.cm.gray_r, interpolation='nearest') 
        plt.title(f"Прогноз: {y_pred[bad_test_index]}\nРеальна: {y_test[bad_test_index]}")
        plt.axis('off')
    plt.show()
else:
    print("Усі прогнози були правильними! (Або немає помилкових прогнозів для відображення).")